사고범위 문제(思考範圍問題,영어:frame problem, 프레임 문제)는인공지능에서 중요한 문제의 하나로, 유한한 정보처리능력을 지닌 로봇이 현실에서 일어날 수 있는 모든 문제에 대해 대처하지 못하는 문제를 말한다.1969년존 매카시와패트릭 헤이즈가,Some Philosophical Problems from the Standpoint of Artificial Intelligence→인공지능 관점에서의 몇몇 철학적 문제들[1]에 서술한 것이 최초이며, 현재는 정형화된 것들이 여러가지 있다.현실 세계에서 인공지능에게 '패스트푸드점에서햄버거를 사오시오.'와 같은 문제를 해결하라고 요구했다고 생각해보자. 현실 세계에서는 그 과정에서 무수하게 다양한 사건이 일어날 가능성이 있지만, 대부분은 당면한 문제와 관계가 없다. 인공지능은 일어날 수 있는 사건 중에서, 패스트푸드점의 햄버거를 사는 일에 관계된 것만을 추출해내고, 그 외의 일은 당분간 염두에 두지 않아야 한다. 모든 사건들을 고려하려면 무한한 시간이 걸리기 때문이다. 즉, 어떤 테두리를 만들고, 그 테두리 안에서만 사고할 필요가 있다.이것이 프레임 문제이다.미리 프레임을 여러개 정해 두어, 상황에 따라 적절한 프레임을 선택해 사용하면 해결할 수 있는 것으로 생각되기도 하지만, 어느 프레임을 현재의 상황에 적용해야 할 것인가 판단하는 시점에서도 같은 문제가 발생한다.아래는철학자다니엘 데넷이Cognitive Wheels&#160;: The Frame Problem of AI→인지 굴레: 인공지능의 사고범위 문제[2]에 실은 예시이다.상황: 동굴 안에,로봇을 움직이는배터리가 있고, 그 위에시한폭탄이 설치되어 있다. 그대로 두면 폭탄이 폭발하여 로봇이 움직이지 못하게 되어 버리므로, 동굴에서 배터리를 꺼내와야만 한다. 로봇은 '동굴에서 배터리를 꺼내올 것'을 지시받았다.인공지능 로봇 1호기 R1은 잘 프로그램되어 있기 때문에, 동굴에 들어가 배터리를 꺼내올 수 있는 능력이 있다. 그러나, 1호기는 배터리 위에 폭탄이 얹혀 있다는 것을 인식은 하고 있었지만, 배터리를 옮기면 폭탄도 함께 옮겨진다는 것은 인식하지 못했기 때문에, 동굴에서 나온 후에 폭탄이 폭발하여 파괴되었다. 이것은 1호기가 배터리를 꺼낸다는 목적에 대해서는 이해하고 있었지만, 거기에 따라 부차적으로 발생하는 사항(배터리를 꺼내면 폭탄도 동시에 옮겨지는 것)에 대해 이해하지 못했던 것이 원인이다.그래서 목적을 수행하는 시기에 부차적으로 발생하는 사항도 고려하는 인공지능 로봇 2호 R1-D1[3]를 개발했다. 그러나 이 로봇은 동굴에 들어가 배터리의 앞에 도착하더니 동작을 멈추고 그대로 있다가 시한폭탄이 폭발하자 파괴되었다. 2호기는 배터리의 앞에서 '이 배터리를 움직이면 위에 있는 폭탄이 폭발하는가', '배터리를 움직이기 전에 폭탄을 이동시켜야 하는가', '폭탄을 움직이려고 하면, 천정이 무너져 내리지는 않는가', '폭탄에 가까워지면 벽의 색깔이 바뀌지 않는가' 등, 부차적으로 발생할 수 있는 모든 사항을 생각하기 시작하여 결국 무한히 계속 사고하게 된 것이다. 이것은, 부차적으로 발생할 수 있는 사항이 무한히 있기 때문에, 그것들을 모두 고려하려면 무한한 처리 시간이 필요하기 때문이다. 다만 부차적으로 발생하는 사항이라고 해도 '벽의 색깔이 바뀌지 않는가'와 같은 것들은 보통 고려할 필요가 없다.그래서 목적을 수행하는 시기에 관계 없는 사항을 고려하지 않게 개량한 인공지능 로봇 3호기 R2-D1를 개발했다. 그러나 이 로봇은 동굴에 들어가기 전에 동작을 멈추었다. 3호기는 동굴에 들어가기 전, 목적과 관계없는 사항을 모두 밝혀내려고 검토를 계속한 것이다. 이것은 목적과 관계없는 사항이라는 것들도 무한히 있기 때문에, 그것들을 모두 고려하려면 무한한 계산 시간이 필요하기 때문이다.